MIT Calculus Course
18.01
https://zh.wikipedia.org/wiki/%E5%BE%AE%E7%A7%AF%E5%88%86%E5%AD%A6


$$f(x) = \frac{d}{dx} \int_{a}^{x} f(t) dt$$

微积分描述了函数局部变化
解决的是==仅以代数和几何学==无法处理的问题
例如：
![[Pasted image 20260129211942.png]]

![[Pasted image 20260129212005.png]]

古代的阿基米德用的是穷竭法计算

对于规则的形状我们是以代数公式解决，例如

![](data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==)
$$ 

𝐴=𝑏\cdot H$$
$$
𝐴=𝜋𝑟2
$$
对于曲线：

**解决方案**：提出微积分正是解决这类问题的数学工具。它处理的是**连续变化率**和**累积量**
对于曲线下的面积，微积分的思路是将其切分成**无数个极小的矩形**，然后将它们的面积**累加**起来。这个过程称为**积分 (Integration)**
![[Pasted image 20260129212902.png]]

当$dx$无限小的时候，我们可以将这一小块面积类似为矩形

也就是$$S矩形=dx \cdot h$$
因此我们很容易发现整个上部分的面积可以将无数小的矩形叠加即可。


至于h
它其实就是**两条曲线在某一点的纵坐标之差**
用抛物线的纵坐标减去直线的纵坐标
由于函数的自变量对应唯一的函数值，这意味我们只需要掌握一个x即可。则
$$S矩形 = h \cdot dx = [f(x) - g(x)] \cdot dx$$
将所有这些无限小的矩形面积累加（求和），用积分符号 $\int$ 表示：
$$S = \int_{a}^{b} [f(x) - g(x)] \, dx$$

以下引用维基百科：[黎曼和](https://zh.wikipedia.org/wiki/%E9%BB%8E%E6%9B%BC%E7%A7%AF%E5%88%86)

>**Riemann Sums**
**黎曼和**
让函数 $f$ 为定义在区间 $[a,b]$ 的非负函数，我们想要计算 $f(x)$所代表的[曲线](https://zh.wikipedia.org/wiki/%E6%9B%B2%E7%BA%BF "曲线")与 $x$跟两条垂直线 $x=a$ 跟 $x=b$所夹图形的[面积](https://zh.wikipedia.org/wiki/%E9%9D%A2%E7%A7%AF "面积")（既右图区域 $S$ 的面积），可将区域 $S$的面积以下面符号表示：
![[Pasted image 20260130195027.png]]
黎曼积分的基本概念就是对 $x$-轴的分割越来越细，则其所对应的矩形面积和也会越来越趋近图形 $S$ 的面积

很明显我们可以发现黎曼和的形式是与我们最后的结果高度吻合

实际上黎曼和只是一个**近似值**
当我们切割的矩形越小，黎曼和的值就越接近我们最后想要得到的结果。
因此我们可以说：这样一个不断将$dx$逼近0的，并且求得最后黎曼和的过程我们称之为==积分==

为了把这段话写进教科书，数学家通常会把它写成下面这个样子：
$$S = \lim_{\Delta x \to 0} \sum_{i=1}^{n} f(x_i^*) \Delta x = \int_{a}^{b} f(x) \, dx$$

我们上述所说的不断逼近0 变成了数学里的$\lim_{\Delta x \to 0}$（极限）



简要提及这种将复杂问题分解为无数小块然后累加的思想，在计算机图形学（如光线追踪中的采样）和数值模拟中非常普遍。


## 求导和求面积的联系

在历史上，求导和求面积本来是完全独立的命题。直到牛顿和莱布尼兹发现了他们之间的桥梁
微积分基本定理（Fundamental Theorem of Calculus）


牛顿莱布尼兹同时发现了这个定理，但是他们的切入角度完全不同

牛顿是从物理运动切入，莱布尼丝则是从几何逻辑切入的
牛顿当初是为了解决天体力学问题发明的微积分
### 核心文献考证：《流数法》（_Method of Fluxions_）

这是牛顿微积分思想最直接的记录。虽然他在 1671 年左右就完成了这部著作，但直到 1736 年才正式出版。
在这本书中，牛顿明确使用了 **"Fluents"（流态）** 和 **"Fluxions"（流数）** 这两个术语。

**流态 ($x, y$)**：代表随时间持续变化的量（比如位移）
**流数 ($\dot{x}, \dot{y}$)**：代表这些量变化的瞬时速度
![[Pasted image 20260130211624.png]]



运动学（kinematics）顾名思义是描述物体运动规律的学问。运动学仅关心如何描述运动，**而不考虑**力与运动的关系。例如，开普勒三大定律：


```
1.行星沿着椭圆轨道运动，太阳位于椭圆轨道的一个焦点。
2.行星到太阳的连线在相同时间内扫过的面积相等。
3.行星绕太阳运动的周期 𝑇 的平方与该行星的椭圆轨道的半长轴 𝑎 的立方成正比
```
上面的三条规律完全可以从观测得到（实验事实），而不涉及行星运动的原因。 因此，**测量**是运动学的基础


同样的，这是笔者妹妹的初中二年级，人教版教材八年级教材的描述：
![[扫描件_第3节_001.jpg]]
路程和时间则是简化过后更适合初等年级的观测量的描述

在高中，我们引入了自由落体运动
![[Pasted image 20260130215659.png]]
在我们观测的位移和时间维度(实验事实)上我们可以得出一条抛物线。


进一步思考，图像上的每一个点是我们通过**观测**得到的，回忆一下高中通过实验我们观测的**时间**越短，得出的点便会越多，相应的点就会越**粘稠**，这一点使得我们相信，可以用曲线来描述落体运动以及 **一般运动**，而不需要明确标定测量的点。

在牛顿之前，人会一般只会用平均速度去衡量运动的快慢，
牛顿的核心突破在于：如果让 $\Delta t$ 变得**无限小**（即图片中绿色的三角形不断缩小直到消失），那么这根蓝色的斜线就会变成曲线在某一点的**切线**
这个过程也是我们所说的**微分**

同样的这张自由落体图，在时间 $t$ 时，位移是 $S(t)$
过了极短的时间 $dt$ 后，位移变成了 $S(t + dt)$
这一瞬间位移的**微小变化**是 $dS = S(t+dt) - S(t)$
根据速度的定义，这一瞬间的速度 $v(t) = \frac{dS}{dt}$，所以有：

$$dS = v(t) \cdot dt$$

实际上我们可以划出速度时间图实际上就是一个正比例函数的图象
![[Pasted image 20260131113459.png]]
在我们切的极小的一段时间里，虽然速度在变，但因为 $dt$ 太小了，我**假装**这dt秒钟内速度是恒定的，数值就是 $v$
![[Pasted image 20260131113651.png]]
这个**速度值 $v$** 就是矩形的**高 $h$**。
这个**时间间隔 $dt$** 就是矩形的**宽**。
**矩形的面积** 也就是 **位移的变化量**（也就是我们位移图上 $x$ 轴下降的那一丁点距离 $\Delta x$）。
**“物体走过的总路程”**（位移图的坐标差值） **等于** **“把每一瞬间的速度累加起来”**（速度图的矩形面积之和）
无数的矩形的面积和

实际上本方法在人教版教材物理必修一出现过

![[Pasted image 20260131113835.png]]

我们再来看我们最开始的这个公式
$$S = \lim_{\Delta x \to 0} \sum_{i=1}^{n} f(x_i^*) \Delta x = \int_{a}^{b} f(x) \, dx$$
fx和dx我们可以发现其实就是对应的vt和dt
那么实际上从代数和几何还有物理意义上被统一起来了

- 在**几何**上，它是“高 $\times$ 宽”，结果是**面积**。
    
- 在**物理**上，它是“速度 $\times$ 时间”，结果是**位移**

如何求？显而易见
通过我们所学的知识和上面的所有回顾，微分实际上是降维的过程，而积分是升维的过程

- **降维（微分）：** 当你观察位移函数 $S(t)$ 时，你关心的是它的“局部倾斜程度”。你通过求导，把位移（米）降维成了速度（米/秒）。
    
    - 数学表达：$S(t) \xrightarrow{\text{降维/导数}} v(t)$。
        
- **升维（积分）：** 现在你手里只有速度 $v(t)$（即你图 1 里的高度 $h$）。你想知道这段时间内总共走了多少米。
    - 你要做的，就是把这些瞬时的、碎片化的速度（低维信息），重新拼接、累积，还原回那个宏观的、总量的位移（高维信息）。
        
    - 数学表达：$v(t) \xrightarrow{\text{升维/积分}} S(t)$。


我们想要求 $v(t)$ 曲线下的**面积**
我们已经知道，这个面积的物理意义就是**总位移的改变量** $\Delta S$
那么，什么函数能直接告诉我们位移的改变量呢？当然是**位移函数 $S(t)$** 本身！

锁定目标：既然我们需要 $S(t)$，而我们已知 $S(t)$ 的**导数**（降维结果）恰好就是速度 $v(t)$

这就是牛顿莱布尼茨公式的原理






推荐书籍：
**微积分的力量**
**(Infinite Powers)** —— _斯蒂芬·斯特罗加茨 (Steven Strogatz)_
 现代科普神作。书中用极其通俗的语言还原了牛顿如何从运动学（变化率）切入，以及莱布尼茨如何从求和（面积）切入的过程


**普林斯顿微积分读本**
最广为人之的微积分读本

3bulebrown 

---
计算机的运用


## 机器学习与深度学习：梯度下降
当你训练一个神经网络（如大语言模型或图像识别模型）时，本质上是在寻找一个**损失函数 $L$** 的最小值

**微分的作用（降维找方向）：** 计算机通过对损失函数求偏导数（计算**梯度**），得知此时模型参数应该往哪个方向移动才能让误差减小



### 前置知识：

**偏导数**：从初中我们就知道函数可以有多个自变量，我们称之为多元函数，尤其是在机器学习中，一个模型可能有数亿个参数（权重 $w_1, w_2, \dots$）
假装其他变量都是死人（常数），只看其中一个变量变动时，整体结果怎么变
**符号：** $\frac{\partial f}{\partial w}$（读作“偏 $f$ 偏 $w$”)

**梯度**：就是把所有变量的偏导数打包成一个向量。它指向函数**增长最快**的方向

相关推荐
https://www.youtube.com/watch?v=IHZwWFHWa-w


**算法逻辑：**
我们想要最小化“损失函数”（也就是预测值和真实值之间的差距）。

1. 计算当前位置的梯度。
    
2. **反向操作**：既然梯度指向“山上”，那我们就往梯度的**负方向**走一步。
    
3. 公式：$w_{new} = w_{old} - \eta \cdot \frac{\partial Loss}{\partial w}$ （$\eta$ 是步长，即学习率）